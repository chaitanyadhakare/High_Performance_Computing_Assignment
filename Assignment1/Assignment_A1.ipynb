{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opzp2twrxN9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRNRqpszzMN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgkwJRVk0kkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xViXeik0_iG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7c5eebdf-30bd-47e9-fdfa-20043df3c213"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-kp3llobe\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-kp3llobe\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=cce05dec43bc507bef526f85898c357d05bc2e60774d60e1836bd66cdac72a89\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yboxfh5h/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F4nHvK51Ff8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c23c979-fcf4-4e1a-8f6d-087e56b02e59"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkYB4RPmSw0C",
        "colab_type": "text"
      },
      "source": [
        "### Assignment A1:  Implement Parallel Reduction using Min, Max, Sum and Average operations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssQQ7p1d-Hm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2b2ec742-a567-4f60-914d-1e69d1421e04"
      },
      "source": [
        "%%cu\n",
        "\n",
        "        \n",
        "#include<iostream>\n",
        "#include<cstdio>\n",
        "#include<cstdlib>\n",
        "#include<cuda_runtime.h>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void minimum(int *input)\n",
        "{\n",
        "\tint tid=threadIdx.x;\n",
        "\tauto step_size=1;\n",
        "  int number_of_threads=blockDim.x;\n",
        "  \n",
        "  while(number_of_threads>0)\n",
        "  {\n",
        "      if(tid<number_of_threads)\n",
        "      {\n",
        "          int first=tid*step_size*2;\n",
        "          int second=first+step_size;\n",
        "          if(input[second]<input[first])\n",
        "            input[first]=input[second];\n",
        "      }\n",
        "      step_size=step_size*2;\n",
        "      number_of_threads/=2;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void max(int *input)\n",
        "{\n",
        "   int tid=threadIdx.x;\n",
        "   auto step_size=1;\n",
        "   int number_of_threads=blockDim.x;\n",
        "   \n",
        "   while(number_of_threads>0)\n",
        "   {\n",
        "       if(tid<number_of_threads)\n",
        "       {\n",
        "           int first=tid*step_size*2;\n",
        "           int second=first+step_size;\n",
        "           if(input[second]>input[first])\n",
        "            input[first]=input[second];\n",
        "       }\n",
        "       step_size*=2;\n",
        "       number_of_threads/=2;\n",
        "   }\n",
        "}\n",
        "\n",
        "__global__ void sum(int *input)\n",
        "{\n",
        "    const int tid=threadIdx.x;\n",
        "    auto  step_size=1;\n",
        "    int number_of_threads=blockDim.x;\n",
        "    while(number_of_threads>0)\n",
        "    {\n",
        "        if(tid<number_of_threads)\n",
        "        {\n",
        "            const int first=tid*step_size*2;\n",
        "            const int second=first+step_size;\n",
        "            input[first]=input[first]+input[second];\n",
        "        }\n",
        "    step_size = step_size*2;; \n",
        "\t\tnumber_of_threads =number_of_threads/2;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void average(int *input)\n",
        "{\n",
        "    const int tid=threadIdx.x;\n",
        "    auto  step_size=1;\n",
        "    int number_of_threads=blockDim.x;\n",
        "    int totalElements=number_of_threads*2;\n",
        "    while(number_of_threads>0)\n",
        "    {\n",
        "        if(tid<number_of_threads)\n",
        "        {\n",
        "            const int first=tid*step_size*2;\n",
        "            const int second=first+step_size;\n",
        "            input[first]=input[first]+input[second];\n",
        "        }\n",
        "        step_size = step_size*2;; \n",
        "\t\tnumber_of_threads =number_of_threads/2;\n",
        "    }\n",
        "    input[0]=input[0]/totalElements;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint n;\n",
        "\tn=100;\n",
        "  cout<<\"No of Elements: \"<<n<<endl;\n",
        "  srand(n);\n",
        "\tint *arr = new int[n];\n",
        "\tfor(int i=0;i<n;i++)\n",
        "\t{\n",
        "\t\tarr[i]=rand()%20000;\n",
        "\t}\n",
        "\n",
        "\tint size=n*sizeof(int); //calculate no. of bytes for array\n",
        "\tint *arr_d,result1;\n",
        "\t\n",
        "  //#max operation\n",
        "  int *arr_max,maxValue;\n",
        "  cudaMalloc(&arr_max,size);\n",
        "\tcudaMemcpy(arr_max,arr,size,cudaMemcpyHostToDevice);\n",
        "  //#calling kernel max function\n",
        "  max<<<1,n/2>>>(arr_max);\n",
        "\tcudaMemcpy(&maxValue,arr_max,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\tcout<<\"Maximun: \"<<maxValue<<endl;\n",
        "\n",
        "  //#min Operation\n",
        "\tcudaMalloc(&arr_d,size);\n",
        "\tcudaMemcpy(arr_d,arr,size,cudaMemcpyHostToDevice);\n",
        "  //#calling minimum kernel function\n",
        "  minimum<<<1,n/2>>>(arr_d);\n",
        "\tcudaMemcpy(&result1,arr_d,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\tcout<<\"Minimum: \"<<result1<<endl;\n",
        "    \n",
        "  //#sum operation\n",
        "  int *arr_sum,sumValue;\n",
        "  cudaMalloc(&arr_sum,size);\n",
        "\tcudaMemcpy(arr_sum,arr,size,cudaMemcpyHostToDevice);\n",
        " //#calling kernal function\n",
        "  sum<<<1,n/2>>>(arr_sum);\n",
        "\tcudaMemcpy(&sumValue,arr_sum,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\tcout<<\"Sum: \"<<sumValue<<endl; \n",
        "  //cout<<\"Average:  \"<<(sumValue/n)<<endl; \n",
        "   \n",
        "  //#avg operation\n",
        "  int *arr_avg,avgValue;\n",
        "  cudaMalloc(&arr_avg,size);\n",
        "\tcudaMemcpy(arr_avg,arr,size,cudaMemcpyHostToDevice);\n",
        "  //#calling kernal function\n",
        "  average<<<1,n/2>>>(arr_avg);\n",
        "\tcudaMemcpy(&avgValue,arr_avg,sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\tcout<<\"Average: \"<<avgValue<<endl; \n",
        "  \n",
        "   \n",
        "  //# Free all allcated device memeory\n",
        "   cudaFree(arr_d);\n",
        "   cudaFree(arr_sum);\n",
        "   cudaFree(arr_max);\n",
        "   cudaFree(arr_avg);\n",
        "  \n",
        "return 0;\n",
        "\n",
        "}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of Elements: 100\n",
            "Maximun: 19936\n",
            "Minimum: 180\n",
            "Sum: 633114\n",
            "Average: 6331\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}